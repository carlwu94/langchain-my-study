from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma

embedding = OllamaEmbeddings(
    model="qwen3-embedding:4b"
)
vector_store = Chroma(
    collection_name = "example_collection",
    embedding_function = embedding,
    persist_directory = "./chroma_langchain_db"
)

# 1.ç›¸ä¼¼åº¦æŸ¥è¯¢
# results = vector_store.similarity_search(
#     "ä¸‰èŠ±æ™ºæŽ§çš„æœ€å¤§æŒè‚¡è‚¡ä¸œæ˜¯è°ï¼Ÿ"
# )
# for index, result in enumerate(results):
#     print ("ðŸ’¡", index)
#     print (result.page_content)


# 2.å¸¦åˆ†æ•°çš„ç›¸ä¼¼åº¦æŸ¥è¯¢
# results = vector_store.similarity_search_with_score(
#     "Vanquishçººè½¦è½®æœ‰å“ªäº›å¼ºå¤§çš„åŠŸèƒ½ï¼Ÿ"
# )
# for (doc, score) in results:  # unpacking tuple
#     print ("ðŸ’¡", score)
#     print (doc.page_content)


# 3.ç”¨å‘é‡è¿›è¡Œç›¸ä¼¼åº¦æŸ¥è¯¢
# vector = embedding.embed_query(
#     "ä¸‡å¥Žå£«å–å¤šå°‘é’±"
# )
# results = vector_store.similarity_search_by_vector(vector)
# for index, result in enumerate(results):
#     print ("ðŸ’¡", index)
#     print (result.page_content)


# 4.ç”¨ä¿®é¥°å™¨è¿›è¡ŒæŸ¥è¯¢
from typing import List
from langchain_core.documents import Document
from langchain_core.runnables import chain

@chain
def retriever(query: str) -> List[Document]:
    return vector_store.similarity_search(query, k=2)

results = retriever.invoke("Shimanoçººè½¦è½®æœ‰å“ªäº›å½“å®¶çš„æŠ€æœ¯ï¼Ÿ")
for index, result in enumerate(results):
    print ("ðŸ’¡", index)
    print (result.page_content)